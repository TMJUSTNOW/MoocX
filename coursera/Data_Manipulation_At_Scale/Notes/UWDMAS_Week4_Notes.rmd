<center> <h2>Data Manipulation At Scale - Week 4</h2> </center>
<center> <h3>---------------------------------------</h3> </center>

####*Video 4.1.1 - NoSQL COntext and Roadmap?*

**A. Notes**

- more typically associated with large-scale web applications, not necessarily data analysis
- a data scientist may be called on to build something like this
    - building data products is important
- databases:
    - key ideas: relational algebra, physical/logical data independence
    - logical independence --> think indexing
- MapReduce:
    - key ideas: fault tolerance, no loading, direct programming on "in situ" data
    - MapReduce requires no schema
    - this is a "single developer" approach, "up and running in an hour"
- some analytics can be pushed into databases and other systems typically thought of as just data management

####*Video 4.1.2 - NoSQL Roundup*

**A. Notes**

- RDBMS didn't scale to 1000s of machines...newer approaches solve this
- in CouchDB, you can scale to many machines and look up by primary and secondary indexes
- if you can do joins, there's a bunch of analytical work you can do
    - a key indicator of how much work can be pushed into the database layer
- SQL-like interactions have a "decorative language"
- RDBMS don't really scale
    - in updates, transaction processing

####*Video 4.1.3 - Relaxing COnsistency Guarantees*

**A. Notes**

- start by chunking the data, replicating chunks across many machines
- we need to ensure:
    - high availability
    - support updates
- changes should propagate to other replicas

**B. Status Change Example**

- DB answer:
    - everyone MUST see the same thing, either old or new, no matter how long it takes
- NoSQL:
    - for large applications, we can't afford to wait arbitrarily long, and maybe it doesn't matter anyway
- the term NoSQL stuck because this is "anti-database" (on the transaction processign sides
    - actually has nothing to do with SQL

####*Video 4.1.4 - Two-Phase Commit and Consensus Protocols*

**A. Notes**

- phase 1:
    - coordinator sends "prepare to commit"
    - subordinates make sure they can do so no matter what
    - subordinates reply "ready to commit"
- phase 2:
    - if all ready, send "commit"
    - if any fail, "abort"
- this can take a while
- failure at the coordinator at the right time can cause bad things
- other protocols:
    - multi-version concurrency control
    - paxos (distirbuted voting scheme)

####*Video 4.1.5 - Eventual Consistency*

**A. Notes**

- write conflicts will eventually propagate throughout the system
- "we believe that applications must be aware that they may read weakly consistent data and also that their write operations may conflict with those of other users and applications"
- in absence of updates, all replicas converge towards identical copies
- what the application sees in the meantime is sensitive to replication mechanics and difficult to predict
- contrast with RDBMS, Paxos: immediate consistency, but there may be deadlocks
- no system can be free of deadlocks and guarantee consistency

####*Video 4.1.6 - CAP Theorem*

**A. Notes**

- Consistency:
    - do all applications see all the same data?
- Availability:
    - can i interact with the system in the presence of failures?
- Partitioning:
    - if two sectiosn of your system cannot talk to each other, can they make forward progress on their own?
- conventional datbases assume no partitioning - clusters were assumed to be small and local
    - assume consistency and availability
- NoSQL systems may sacrifice consistency
- opt for consistency and partitioning:
    - Bigtable, Hbase, Hypertable

####*Video 4.2.1 - Types of NoSQL Systems*

**A. Notes**

- Rick Cattel --> "Scalable SQL and noSQL Data Stores"
- \textbf{Document} = nested values values, extensible records (think XML or JSON)
    - extensible means "you can add stuff whenever you want"
- \textbf{extensible record} = families of attributes have a schema, but new attributes may be added
- \textbf{Key-Value object} = a set of key-value pairs. No schema, no exposed nesting. 

**B. NoSQL Features**

- ability to horizontally scale "simple operation" throughput over many servers,
    - simple = key lookups, read/write of 1 records
- the ability to replicate and partition data over many servers
    - consider "sharding" and "horizontal partitioning"
    - high scale
- a simple API - no decorate query language
    - no SQL
- a weaker concurrency model than ACID transactions
    - no transactions
- efficient use of distributed indexes and RAM for data storage
    - minimizing latency
- the ability to dynamically add new attributes to data records
    - no schema

####*Video 4.2.2 - ACID, Major Impact Systems*

**A. Notes**

- ACID = atomicity, consistency, isolation, durability
    - atomicity = no partial transactions...all fail or all succeed
    - isolation = users only get final states
    - durability - if you say it succeeded, it actually succeeded
- consistency: "Any data written to the database must be valid according to defined rules"

**B. Major Impact Systems**

- \textbf{Memcached} demonstrated that in-memory indexes can be highly scalable, distributing and replicating objects over multiple nodes
- \textbf{dynamo} pioneered the idea of using eventual consistency as a way to achieve higher availability and scalability; data fetched are not guaranteed to be up-to-date, but updates are guaranteed to be propagated to all nodes eventually
    - relaxing consistency lets you scale way way out
- \textbf{BigTable} demonstrated that persistent record storage could be scaled to thousands of nodes, a features that most of hte other systems aspire to.

####*Video 4.2.3 - Memcached: Consistent Hashing*

**A. Notes**

- main-memory caching service
    - basic system: no persistence, replication, fault-tolerance
- mature system, still in wide use
- important concept: consistent hashing

**B. Regular hashing**

- assign M data keys to N servers
- assign each key to server k mod N
    - if you add more servers, every key needs to be remapped, and we're screwed

**C. Consistent Hashing**

- when I place something somewhere it stays there, even if new servers are added

####*Video 4.2.4 - Consistent Hashing, cont'd*

**A. Notes**

- apply some function h(s) to map the server ids into the edges of the data
- assign servers responsibility for "sections of the data"
    - adding new servers requires much less moving

**B. Routing**

- each server should know the key range being managed by other servers
    - this lets you very quickly "hop" aroudn to serve a request
    - much much faster
- logarithmic maintenance

####*Video 4.2.5 - DynamoDB: Vector Clocks*

**A. Notes**

- from Amazon (2007)
- recently released as cloud service DynamoDB
- key features:
    - service level agreement (SLN)
    - at the 99th percentile, and not on mean/median/variance (otherwise, one penalizes the heavy users
    - respond within 300 ms for 99.9 % of requests
- distributed hash table (DHT) with replication:
    - store val at k, k+1, ... K+N-1
    - eventual consistency through vector clocks
- reconciled at read time:
    - writes never fail ("poor customer experience")
    - conflict resolution: "last write wrins" or application specific
    
**B. Vector Clocks**

- just trying to detect conflicts
- every bit of data tagged with server, timestamp pairs
- each data item associated with a list of (server, timestamp) pairs indicating its version history
- looking at pairs of "same server, same timestamp" to detect conflicts

####*Video 4.2.6 - Vector Clocks, cont'd*

**A. Notes**

- no conflicent if "one strictly later than the other on all shared servers"

**B. Configureable Consistency**

- R = minimum number of nodes that participate in a successful read
- W = minimum number of nodes that participate in a succcesful write
- N = replication factor
- R + w > N, you can claim consistency
- but R + W < N, means lower latency

####*Video 4.3.1 - CouchDB Overview*

**A. Notes**

- started in 2005
- scales and allows primary and secondary indexes
- some support of analytics (you can run some MapReduce scripts in CouchDB views)
- document-oriented data model (document = set of key/value pairs)
- all data represented in JSON, all requests come back in JSON

**B. CouchDB: Updates**

- full consistency within a document
- lock-free concurrency:
    - optimistic: attempts to edit dirty data fail
- no multi-row transactions
    - transaction: sequence of related updates
    - entire sequence considered ACID
    - no "update my status and all my friends' walls"

####*Video 4.3.2 - CouchDB Views*

**A. Notes**

- a view is itself a couchDB document (in JSON)
- mapReduce written in Javascript
- you can even do some computation/analytics
    - but not joins

####*Video 4.3.3 - BigTable Overview*

**A. Notes**

- developed by Google (2006)
- compatible with MapReduce (in HBase)
- no views, no algebra level
    - all mostly NoSQL-style micro interactions
- the idea was for it to be complementary to MapReduce
- MapReduce doesn't support indexing
    - you have to touch every single record
- data model = "a sparse, distributed, persistent multi-dimensional sorted map"
    - (row:string, column:string, time:int64) --> string

**B. Rows**

- data sorted lexicographically by row key
- row key range broken into "tablets"
- a tablet is the unit of distribution and load balancing
- unlike Teradata, records close to each other in time will be likely to end up on the same server
- downside:
    - if all the recent data are on a few servers and those are most popular, you might have some 

####*Video 4.3.4 - BigTable Implementation*

**A. Notes**

- column names of the form family:qualifier
- "family" is the basic unit of:
    - access control
    - memory accounting
    - disk accounting
- typically all columns in a family the same type

**B. Timestamps**

- each cell can be versioned
- each new version increments the timestamp

**C. Table Management**

- tablet server manages reads and write from tables
- tablet server splits tablets that have grown too large
- there is a "root table" with metadata describing the location of other records
- "chubby file" --> a distributed lock service for controlling access

**D. Write Processing**

- a table in memory stores a sequence of updates as they occury
- writes are written to a log for fault tolerance purposes
- major compaction: rewrite all SSTables into one SStable: clean deletes
- minor compaction (where memtable gets big): write memtable buffer to a new SSTable

**E. Other tricks**

- compression
- bloom filters
    - fast set membership test for row,column pair
    - reduces disk accesses during reads
- locality groups
    - groups of column families frequently accessed together
- SSTables are immutable
    - only the memtable needs to support concurrent updates

####*Video 4.4.1 - HBase, Megastore*

**A. Notes**

- implementation of Google BigTable as open-soruce project
- compatible with Hadoop
    - TableInputFormat allows reading of BigTable data in the map phase
    - one mapper per tablet
    - Aside: speculative execution?...for fault tolerance reasons, the same map task might execute in two places
    - no system-wide consistency guarantees

**B. Megastore**

- argues that loose consistency model complicate application programming
- synchronous replication
- entity group --> set of records that tend to be accessed together
    - full transactions within a partition

####*Video 4.4.2 - Spanner*

**A. Notes**

- Bigtable can be difficult to use for some kinds of applications;
    - those that have complex, evolving schema
    - those that want strong consistency in the presence of wide-area replication
- transactions are difficult, error prone, expensive, and "wrong" at the application level
- "although Spanner is scalable in the number of nodes, the node-local data structures have relatively poor performance on complex SML queries
- Spanner is a "plant-scale" systems
- joins might be suppoerted
- SQL-like decorative language

**B. Data Model**

- directories: set of contiguous keys with a shared prefix
- we're making our way toward a big, scalable relational database

####*Video 4.4.3 - Spanner cont'd, Google Systems*

**A. Notes**

- there is a "placement driver" that moves directories around for load balancing
- "Zone" --> an individual BigTable deployment
- fully consistent transactiosn supported, via. 2-phase commit

####*Video 4.4.4 - MapReduce-based Systems*

**A. Notes**

- decorative languages on top of mapreduce are here to stay
- enterprises have made a big investment in SQL expertise in the past
- languages added to Hadoop:
    - Pig
    - Hive
- there are potentially 100s of extensions to MapReduce
- Dremel is the back end of "query as a service" Google BigQuery
- Spark/Shark come from Berkeley's AmpLab
- Berkeley analytics stack (BADASS)
- Shark is SQL on top of Spark
- CouchDB = document-oriented

####*Video 4.4.5 - Bringing Back Joins*

**A. Notes**

- "Joins/Analytics"
    - if you can do joins, you can do analytics
    - joins usually not suppoorted in NoSQL
- tensions between buying a bit of performance by organizing the data in a rigid way vs. saving development time by giving up on schema
- leaving the programmer to make a decisions about how to access the data is asking them to do something that they aren't equipped to do:
    - only the system knows itself

####*Video 4.4.6 - NoSQL Rebuttal*

**A. NoSQL Criticism**

- two value props:
    - performance: I Started with MySQL, but had a hard time scaling it out in a distirbuted environment
    - flexibility: my data doesn't conform to a rigid schema
- who are NoSQL customers?
    - web startups
- most applications are traditional online transaction processing (OLTP)
- No ACID equals no interest
    - screwing up mission-critical data is no-no-no
- Low-level Query language is death
    - remember CODASYL?
- NoSQL means NoStandards
    - one typical large enterprise has 10,000 databases
    - these need accepted standards
- LOTS of decisions in designing NoSQL
    - these complication integration and standards

####*Video 4.5.1 - Almost SQL: Pig*

**A. Notes**

- an engine for executing programs on top of Hadoop
- it provides a language, Pig Latin, to specify these programs
- an Apache open souce project: http;//pig.apache.org/
- a Pig programs generates a sequence of MapReduce programs
- Pig is a sort of "decorative language" for Hadoop
    - "almost SQL"
    - relational algebra

####*Video 4.5.2 - Pig Architecture and Performance*

**A. Notes**

- lazy evaluation --> nothing happens until you try to write out to a file
- the game is to minimize the number of MapReduce jobs (setting those up require overhead)
- MapReduce jobs scheduled on a Hadoop server
- "'there is a cost to abstraction", but you can recover some productivity

####*Video 4.5.3 - Data Model*

**A. Notes**

- atom: integer, string, etc.
- tuple:
    - sequence of fields of any type
- bag:
    - collection of tuples (need not be same type)
    - bag not a set (duplicates allowed)
- map:
    - string literal keys mapped to any type
    - like a Python dictionary
- some notes on Pig syntax in this video
- not relational...closer to R or MATLAB nested data types

####*Video 4.5.4 - Load, Filter, Group*

**A. Notes**

####*Video 4.5.5 - Group, Distinct, Foreach, Flatten*

**A. Notes**

####*Video 4.6.1 - CoGroup, Join*

**A. Notes**

####*Video 4.6.2 - Join Algorithms*

**A. Notes**

####*Video 4.6.3 - Skew*

**A. Notes**

####*Video 4.6.4 - Other Commands*

**A. Notes**

####*Video 4.6.5 - Evaluation Walkthrough*

**A. Notes**

####*Video 4.6.6 - Review*

**A. Notes**

####*Video 4.7.1 - Spark: Context*

**A. Notes**

####*Video 4.7.2 - Spark Examples*

**A. Notes**

####*Video 4.7.3 - RDDs, Benefits*

**A. Notes**

####*Video 4.8.1 - Graph Overview*

**A. Notes**

####*Video 4.8.2 - Structural Analysis*

**A. Notes**

####*Video 4.8.3 - Degree Histograms, Structure of the Web*

**A. Notes**

####*Video 4.8.4 - Connectivity and Centrality*

**A. Notes**

####*Video 4.9.1 - PageRank*

**A. Notes**

####*Video 4.9.2 - PageRank in More Detail*

**A. Notes**

####*Video 4.9.3 - Traversal Tasks: Spanning Trees and Circuits*

**A. Notes**

####*Video 4.9.4 - Traversal Tasks: Maximum Flow*

**A. Notes**

####*Video 4.10.1 - Pattern Matching*

**A. Notes**

####*Video 4.10.2 - Querying Edge Tables*

**A. Notes**

####*Video 4.10.3 - Relational Algebra and Datalog for Graphs*

**A. Notes**

####*Video 4.10.4 - Querying Hybrid Graph/Relational Data*

**A. Notes**

####*Video 4.10.5 - Graph Query Example: NSA*

**A. Notes**

####*Video 4.11.1 - Graph Query Example: Recursion*

**A. Notes**

####*Video 4.11.2 - Evaluation of Recursive Programs*

**A. Notes**

####*Video 4.11.3 - Recursive Queries in MapReduce*

**A. Notes**

####*Video 4.11.4 - The End-Game Problem*

**A. Notes**

####*Video 4.12.1 - Representation: Edge Table, Adjacency List*

**A. Notes**

####*Video 4.12.2 - Representation: Adjacency Matrix*

**A. Notes**

####*Video 4.12.3 - PageRank in MapReduce*

**A. Notes**

####*Video 4.12.4 - PageRank in Pregel*

**A. Notes**

