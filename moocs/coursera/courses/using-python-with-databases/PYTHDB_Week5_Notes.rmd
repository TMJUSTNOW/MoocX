<center> <h2>Using Databases with Python - Week 5</h2> </center>
<center> <h3>---------------------------------------</h3> </center>

####*Video 5.1 - Geocoding*

**A. Notes**

- the use of databases: data process can break/stop/take forever
- real-world problems aren't handled in a single program...we use compositions of programs
- cached = local copy

####*Video 5.2 - Page Rank and Web Searching*

**A. Notes**

- the PageRank algorithms values links
- we are going to create a simple version of PageRank and visualize the resulting network
- http://infolab.stanford.edu/~backrub/google.html
- we're going to do web crawling, indexing, search
- a "web crawler" is a program that browses the Web in a methodical, automated manner
- steps:
	- get a page
	- look through all the links on the page
	- add new links to the "yet to be retrieved" list
- some sites use a "robots.txt" file to tell crawlers to leave
- the data live on disk, so we can constantly break and restart this thing

####*Video 5.3 - Gmane - Mailing Lists*

**A. Notes**

- we'll crawl the mailing list archive, do some preprocessing, and then do some visualization
- it might be better to do the cleaning in an intermediate step between DBs (rather than on import)
- d3.js is cool because it works in the browser

####*Video 5.4 - GeoCoding API Demo*

**A. Notes**

- remember you can use ```urllib.urlencode()``` to map key-value pairs into their URL equivalents
- 

####*Video 5.5 - BONUS: Richard Stallman - Free Software Foundation*

####*Video 5.6 - BONUS: Brian Behlendorf - Apache Foundation*


