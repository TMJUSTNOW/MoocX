One of the major discoveries of the twentieth century was that deterministic systems could be inherently unpredictable.

In the 1960s the weather scientist [Edward Lorenz](https://en.wikipedia.org/wiki/Edward_Norton_Lorenz) observed that minute variations in the initial values of variables in his twelve-variable computer weather model could result in grossly divergent weather patterns:

> Two states differing by imperceptible amounts may eventually evolve into two considerably different states … If, then, there is any error whatever in observing the present state—and in any real system such errors seem inevitable—an acceptable prediction of an instantaneous state in the distant future may well be impossible….In view of the inevitable inaccuracy and incompleteness of weather observations, precise very-long-range forecasting would seem to be nonexistent.

Such *sensitive dependence on initial conditions* means that the further one goes into the future the more inaccurate predictions become. Systems that are sensitive to initial conditions and bounded are said to be *chaotic*.

Discrete systems can also be sensitive to initial conditions. For example, when making a weekly trip you normally wake up at 6:00 a.m., catch the bus at 7:00 a.m., catch the train at 7:30 to catch a plane arriving at your destination at 12:00. However, today you wake up at 6:01 a.m. and miss the 7:00 a.m. bus to arrive on the next one at the station at 7:45 a.m. and miss the train, arriving at the airport after you plane has departed. You have to take the next available plane and arrive 6 hours late.

A *point prediction* says that a system will be a particular state at a precise point in future time. Long-term and even some short-term predictions are meaningless in systems that are sensitive to initial conditions. The best one can do is make statistical predictions. Social systems can be sensitive to initial conditions for many reasons and are usually not point-predictable.

Clocks are systems that are intended to make long-term point predictions, and they are designed *not* to be sensitive to initial conditions.

### Extreme Events

Most systems function within bounds most of the time, and while behaving ‘normally’ they are controllable. However, sometimes systems go wildly outside their normal parameters in what are called *extreme events*. For example, large earthquakes and erupting volcanos are extreme natural events. The financial crash of 2008 was an extreme event in the financial systems due to, it was later discovered, systemic weaknesses in regulation and the creation of financial products that no-one understood.

Some extreme events such as earthquakes are unpredictable. Some extreme events are accidents waiting to happen. Systems thinking can help managers reflect on whether there are risks in their systems and help them to reduce those risks.

### What do you think?

Do you have experience of sensitivity to initial conditions? Have you or someone you know missed an appointment or an event because of this? Give your view and share you experiences in the comments below.

[**](https://www.futurelearn.com/courses/systems-thinking-complexity/3/steps/207364#fl-comments)