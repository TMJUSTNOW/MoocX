{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman Filters\n",
    "\n",
    "Kalman filter can help us track other cars. Kalman filters estimate a continuous state, as a result kalman filters happens to give a unimodal distribution.\n",
    "\n",
    "### Sensors\n",
    "* Spinning Laser range finder: takes distance scans 10x / second, about 1M data points (each time). -> spot cars so you don't run into them.\n",
    "* Camera on top.\n",
    "* Stereo camera system\n",
    "* Antennas for GPS at rear to estimate where car is in the world.\n",
    "\n",
    "### Tracking using Kalman Filters\n",
    "* Kalman filter is similar to Monte Carlo localisation, except it's \n",
    "    * estimates continuous state (as opposed to divided into discrete grids)\n",
    "    * uni-model (as opposed to multi-modal)\n",
    "* Kalman filter estimates future locations based on previous locational datapoints (even if they're noisy).\n",
    "\n",
    "### Gaussian\n",
    "In Kalman filters, the distribution is given by what is called the Gaussian. Gaussian is the continous function over the state of locations and the area underneath sums up to 1.\n",
    "![gaussian](./images/3kalman-filters/gaussian.png)\n",
    "\n",
    "Suppose the 1D space is characterized by x, then gaussian is characterized by 2 parameters - mean and variance.\n",
    "* 1-D Gaussian N(μ, σ^2) -> only need to estimate two parameters.\n",
    "    * μ (or mu) is the mean\n",
    "    * σ^2 (sigma square) is the variance: measure of uncertainty\n",
    "Our task in Kalman Filters is to maintain the mean and covariance as a best estimate of the location of the object we are trying to find.\n",
    "Let A = (x-μ)^2, B = σ^2, C = 1/(2*π^2)^1/2\n",
    "f(x) = C* exp^(-1/2 * A/B)\n",
    "i.e.: \n",
    "![gaussian](./images/3kalman-filters/gaussian-formula.png)\n",
    "\n",
    "#### Comparing the covariance\n",
    "Function with largest covariance has more spread distribution.\n",
    "![gaussian](./images/3kalman-filters/covariance-compare.png)\n",
    "\n",
    "More covariance means, more uncertainity as covariance is measure of uncertainity. We want less uncertainity, so we prefer low-variance Gaussians for locating cars. \n",
    "\n",
    "\n",
    "* Facts:\n",
    "    * Continuous distribution, vs Monte Carlo localisation where distribution estimated by a histogram.\n",
    "    * Area under the Gaussian sums to 1.\n",
    "    * Exponential of a quadratic function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12098536225957168\n"
     ]
    }
   ],
   "source": [
    "# Program the Gaussian\n",
    "from math import *\n",
    "\n",
    "def f(mu, sigma2, x):\n",
    "    return 1/sqrt(2.*pi*sigma2) * exp(-.5 * (x-mu)**2 / sigma2)\n",
    "\n",
    "print(f(10., 4., 8.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kalman Filter\n",
    "The Kalman Filter represents our distributions by guassians and iterates on two main cycles, as with localisation: \n",
    "1. Measurement updates\n",
    "    * [requires product](https://classroom.udacity.com/courses/cs373/lessons/48739381/concepts/487235990923#) - By updating belief by a multiplicative factor (multiplying the Gaussians)\n",
    "    * Uses [Bayes Rule](https://classroom.udacity.com/courses/cs373/lessons/48739381/concepts/487221690923#)\n",
    "2. Prediction (Motion updates in localisation)\n",
    "    * By performing a convolution (addition)\n",
    "    * Uses [total Probability](https://classroom.udacity.com/courses/cs373/lessons/48739381/concepts/486736290923#) to keep track of where all of our probability 'goes' when we move\n",
    "    \n",
    "###  1. Measurement cycle\n",
    "When we move from one point to other, we have 2 different mean and variance. The resulting results are:\n",
    "\n",
    "* Mean:\n",
    "    * The lower the variance of our new measurement, the more weight we give it (pull our prior mean towards the measurement mean).\n",
    "* Variance:\n",
    "    * More measurements -> greater certainty (lower variance). New Gaussian has lower variance than either the prior or the measurement Gaussian.\n",
    "    * As the covariance is less, we have higher peak\n",
    "    * Unaffected by means \n",
    "\n",
    "#### Multiplication of 2 Gaussians as in Bayes rule\n",
    "Suppose we multiple 2 gaussians as in Bayes rule, a prior and measurement probability.\n",
    "prior Gaussian = f(μ, σ^2)\n",
    "measurement has a mean of ν and covariane of r^2\n",
    "Then the new mean is `μ' = (r^2*μ + σ^2*ν) / (r^2 + σ^2)` and new covariance `σ'^2 = 1 / H, where H = 1/r^2 + 1/σ^2`\n",
    "\n",
    "Note that covariance doesn't depend on means.\n",
    "\n",
    "\n",
    "    \n",
    "[](measurement-cycle.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.4, 1.6]\n"
     ]
    }
   ],
   "source": [
    "# Write a program to update your mean and variance\n",
    "# when given the mean and variance of your belief\n",
    "# and the mean and variance of your measurement.\n",
    "# This program will update the parameters of your\n",
    "# belief function.\n",
    "\n",
    "def update(mean1, var1, mean2, var2):\n",
    "    new_mean = (mean1 * var2 + mean2 * var1)/(var1 + var2)\n",
    "    new_var = 1/ (1/var1 + 1/var2)\n",
    "    return [new_mean, new_var]\n",
    "\n",
    "print(update(10.,8.,13., 2.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Motion Update (Prediction)\n",
    "So we have seen the measurement update, which we get as multiplication of 2 gaussians, which is same as Bayes rule.\n",
    "\n",
    "Now we will see motion update, which is done by total probability, i.e. addition.\n",
    "\n",
    "* Suppose you live in a world like this:\n",
    "  ![motion_update1](./images/3kalman-filters/motion_update1.png)\n",
    "* Suppose you move to the right by a certain distance. Your movement has some uncertainty, so variance increases.\n",
    "  ![motion_update2](./images/3kalman-filters/motion_update2.png)\n",
    "  \n",
    "  Now the math for this is very simple\n",
    "\n",
    "```\n",
    "μ'= μ + u\n",
    "σ'^2 = σ^2 + r^2\n",
    "```\n",
    "\n",
    "Here is the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(mean1, var1, mean2, var2):\n",
    "    new_mean = mean1 + mean2\n",
    "    new_var = var1 + var2\n",
    "    return [new_mean, new_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Kalman filter - Putting all together\n",
    "Now we have measurement update and motion's predict function. Now lets get the Kalman filter code.\n",
    "sig suffix is sigma, but we mean `sigma^2` which means covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update:  [4.998000799680128, 3.9984006397441023]\n",
      "Predict:  [5.998000799680128, 5.998400639744102]\n",
      "Update:  [5.999200191953932, 2.399744061425258]\n",
      "Predict:  [6.999200191953932, 4.399744061425258]\n",
      "Update:  [6.999619127420922, 2.0951800575117594]\n",
      "Predict:  [8.999619127420921, 4.09518005751176]\n",
      "Update:  [8.999811802788143, 2.0235152416216957]\n",
      "Predict:  [9.999811802788143, 4.023515241621696]\n",
      "Update:  [9.999906177177365, 2.0058615808441944]\n",
      "Predict:  [10.999906177177365, 4.005861580844194]\n",
      "[10.999906177177365, 4.005861580844194]\n"
     ]
    }
   ],
   "source": [
    "# Write a program that will iteratively update and\n",
    "# predict based on the location measurements \n",
    "# and inferred motions shown below. \n",
    "\n",
    "def update(mean1, var1, mean2, var2):\n",
    "    new_mean = float(var2 * mean1 + var1 * mean2) / (var1 + var2)\n",
    "    new_var = 1./(1./var1 + 1./var2)\n",
    "    return [new_mean, new_var]\n",
    "\n",
    "def predict(mean1, var1, mean2, var2):\n",
    "    new_mean = mean1 + mean2\n",
    "    new_var = var1 + var2\n",
    "    return [new_mean, new_var]\n",
    "\n",
    "measurements = [5., 6., 7., 9., 10.]\n",
    "motion = [1., 1., 2., 1., 1.]\n",
    "measurement_sig = 4. \n",
    "motion_sig = 2.\n",
    "mu = 0.\n",
    "sig = 10000. # initial uncertainity and it is very large\n",
    "\n",
    "#Please print out ONLY the final values of the mean\n",
    "#and the variance in a list [mu, sig]. \n",
    "\n",
    "# Insert code here\n",
    "for i in range(len(measurements)):\n",
    "    mu, sig = update(mu, sig, measurements[i], measurement_sig)\n",
    "    print('Update: ', [mu, sig])\n",
    "    mu, sig = predict(mu, sig, motion[i], motion_sig)\n",
    "    print('Predict: ', [mu, sig])\n",
    "print([mu, sig])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is unexpected that the code is so simple for a Kalman filter in 1D. We pass measurement[i] as mean2 in update and motion[i] as mean2 in predict function.\n",
    "\n",
    "We see that on 1st update, we have mean of 4.998000799680128 aka 5, as we have huge initial uncertainity of 10000, and resulting variance is 3.998 which is better than measurement sig of 4 and initial uncertainity of 10000. \n",
    "For predict, things are simple as this is just an addition. But as mean is increasing from update, it also increases for predict, and as variance is decreasing from update, variance is also decreasing for predict.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-dimensional Kalman Filter\n",
    "To talk about Kalman filters, we have to talk about high dimensional gaussians OR Multivariate Gaussians.\n",
    "\n",
    "* Implicitly figures out velocity from seeing multiple positions, and from that makes predictions about future location.\n",
    "![multi-dimensional-kalman-filter](./images/3kalman-filters/multi-dimensional-kalman-filter.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Gaussians\n",
    "Mean is now a vector for each of the dimension, variance here is replaced by covariance which is a matrix with D rows and D columns if the dimensionality of the estimate is D. \n",
    "\n",
    "#### Formula for Multivariate Gaussians\n",
    "The formula is something you have to get used to:\n",
    "\n",
    "![multivariate-gaussian1](./images/3kalman-filters/multivariate-gaussian1.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g. contour lines of a 2D Gaussian:\n",
    "\n",
    "![multivariate-gaussian3](./images/3kalman-filters/multivariate-gaussian3.png)\n",
    "\n",
    "In the above figure (x0, y0) pair denote mean and contours represent covariance spread.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the figure below, we have small contour denoting fairly small uncertainity. \n",
    "\n",
    "The longer contour denotes that we may have small uncertainity in 1 dimension and large uncertaining in another.\n",
    "\n",
    "![multivariate-gaussian2](./images/3kalman-filters/multivariate-gaussian2.png)\n",
    "\n",
    "Tilted Gaussian (not parallel or perpendicular to x or y axes): x and y correlated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kalman filter prediction\n",
    "Build 2-dimensional estimate: one for location, one for velocity.\n",
    "\n",
    "If we project the new 2D Gaussian into the space of velocity or x, we can't predict the velocity or the location. But this Gaussian expresses that velocity is correlated to location.\n",
    "- img\n",
    "\n",
    "Now we fold in the second observation (green)\n",
    "\n",
    "\n",
    "and we can have our new predicted Gaussians (purple / blue Gaussians on the red Gaussian)\n",
    "\n",
    "\n",
    "- img\n",
    "Subsequent observables give us information about the hidden variables, so we can estimate hidden variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing Kalman Filters\n",
    "* State transition function\n",
    "* Measurement function\n",
    "\n",
    "(img)\n",
    "\n",
    "Kalman Filtetr equations (don't need to know for this course)\n",
    "\n",
    "(img)\n",
    "\n",
    "K: Kalman gain\n",
    "Final lines in red: update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalman Filters Land\n",
    "In Kalman filters land we build 2D estimates - 1 for location and other for velocity denoted x-dot = ẋ.\n",
    "\n",
    "velocity can be 0, +ve or -ve.\n",
    "\n",
    "If initially we know the location but not the velocity, then we can represent the gaussian elevated around the correct location but really really broad in terms of velocity.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kalman Filter Design\n",
    "![multivariate-gaussian-equations](./images/3kalman-filters/kalman-filters-equations-multidim.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kalman filter matrices\n",
    "Below it the class matrix - which initializes matrices and provides operators for addition, subtraction, transpose etc and provides inverse using Cholesky factorization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([[3.9996664447958645], [0.9999998335552873]], [[2.3318904241194827, 0.9991676099921091], [0.9991676099921067, 0.49950058263974184]])\n"
     ]
    }
   ],
   "source": [
    "# Multidimensional Kalman Filter\n",
    "# Write a function 'kalman_filter' that implements a multi-\n",
    "# dimensional Kalman Filter for the example given\n",
    "\n",
    "from math import *\n",
    "\n",
    "class matrix:\n",
    "    \n",
    "    # implements basic operations of a matrix class\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.dimx = len(value)\n",
    "        self.dimy = len(value[0])\n",
    "        if value == [[]]:\n",
    "            self.dimx = 0\n",
    "    \n",
    "    def zero(self, dimx, dimy):\n",
    "        # check if valid dimensions\n",
    "        if dimx < 1 or dimy < 1:\n",
    "            raise ValueError(\"Invalid size of matrix\")\n",
    "        else:\n",
    "            self.dimx = dimx\n",
    "            self.dimy = dimy\n",
    "            self.value = [[0 for row in range(dimy)] for col in range(dimx)]\n",
    "    \n",
    "    def identity(self, dim):\n",
    "        # check if valid dimension\n",
    "        if dim < 1:\n",
    "            raise ValueError(\"Invalid size of matrix\")\n",
    "        else:\n",
    "            self.dimx = dim\n",
    "            self.dimy = dim\n",
    "            self.value = [[0 for row in range(dim)] for col in range(dim)]\n",
    "            for i in range(dim):\n",
    "                self.value[i][i] = 1\n",
    "    \n",
    "    def show(self):\n",
    "        for i in range(self.dimx):\n",
    "            print(self.value[i])\n",
    "        print(' ')\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        # check if correct dimensions\n",
    "        if self.dimx != other.dimx or self.dimy != other.dimy:\n",
    "            raise ValueError(\"Matrices must be of equal dimensions to add\")\n",
    "        else:\n",
    "            # add if correct dimensions\n",
    "            res = matrix([[]])\n",
    "            res.zero(self.dimx, self.dimy)\n",
    "            for i in range(self.dimx):\n",
    "                for j in range(self.dimy):\n",
    "                    res.value[i][j] = self.value[i][j] + other.value[i][j]\n",
    "            return res\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        # check if correct dimensions\n",
    "        if self.dimx != other.dimx or self.dimy != other.dimy:\n",
    "            raise ValueError(\"Matrices must be of equal dimensions to subtract\")\n",
    "        else:\n",
    "            # subtract if correct dimensions\n",
    "            res = matrix([[]])\n",
    "            res.zero(self.dimx, self.dimy)\n",
    "            for i in range(self.dimx):\n",
    "                for j in range(self.dimy):\n",
    "                    res.value[i][j] = self.value[i][j] - other.value[i][j]\n",
    "            return res\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        # check if correct dimensions\n",
    "        if self.dimy != other.dimx:\n",
    "            raise ValueError(\"Matrices must be m*n and n*p to multiply\")\n",
    "        else:\n",
    "            # subtract if correct dimensions\n",
    "            res = matrix([[]])\n",
    "            res.zero(self.dimx, other.dimy)\n",
    "            for i in range(self.dimx):\n",
    "                for j in range(other.dimy):\n",
    "                    for k in range(self.dimy):\n",
    "                        res.value[i][j] += self.value[i][k] * other.value[k][j]\n",
    "            return res\n",
    "    \n",
    "    def transpose(self):\n",
    "        # compute transpose\n",
    "        res = matrix([[]])\n",
    "        res.zero(self.dimy, self.dimx)\n",
    "        for i in range(self.dimx):\n",
    "            for j in range(self.dimy):\n",
    "                res.value[j][i] = self.value[i][j]\n",
    "        return res\n",
    "    \n",
    "    # Thanks to Ernesto P. Adorio for use of Cholesky and CholeskyInverse functions\n",
    "    \n",
    "    def Cholesky(self, ztol=1.0e-5):\n",
    "        # Computes the upper triangular Cholesky factorization of\n",
    "        # a positive definite matrix.\n",
    "        res = matrix([[]])\n",
    "        res.zero(self.dimx, self.dimx)\n",
    "        \n",
    "        for i in range(self.dimx):\n",
    "            S = sum([(res.value[k][i])**2 for k in range(i)])\n",
    "            d = self.value[i][i] - S\n",
    "            if abs(d) < ztol:\n",
    "                res.value[i][i] = 0.0\n",
    "            else:\n",
    "                if d < 0.0:\n",
    "                    raise ValueError(\"Matrix not positive-definite\")\n",
    "                res.value[i][i] = sqrt(d)\n",
    "            for j in range(i+1, self.dimx):\n",
    "                S = sum([res.value[k][i] * res.value[k][j] for k in range(self.dimx)])\n",
    "                if abs(S) < ztol:\n",
    "                    S = 0.0\n",
    "                res.value[i][j] = (self.value[i][j] - S)/res.value[i][i]\n",
    "        return res\n",
    "    \n",
    "    def CholeskyInverse(self):\n",
    "        # Computes inverse of matrix given its Cholesky upper Triangular\n",
    "        # decomposition of matrix.\n",
    "        res = matrix([[]])\n",
    "        res.zero(self.dimx, self.dimx)\n",
    "        \n",
    "        # Backward step for inverse.\n",
    "        for j in reversed(range(self.dimx)):\n",
    "            tjj = self.value[j][j]\n",
    "            S = sum([self.value[j][k]*res.value[j][k] for k in range(j+1, self.dimx)])\n",
    "            res.value[j][j] = 1.0/tjj**2 - S/tjj\n",
    "            for i in reversed(range(j)):\n",
    "                res.value[j][i] = res.value[i][j] = -sum([self.value[i][k]*res.value[k][j] for k in range(i+1, self.dimx)])/self.value[i][i]\n",
    "        return res\n",
    "    \n",
    "    def inverse(self):\n",
    "        aux = self.Cholesky()\n",
    "        res = aux.CholeskyInverse()\n",
    "        return res\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return repr(self.value)\n",
    "\n",
    "\n",
    "########################################\n",
    "\n",
    "# Implement the filter function below\n",
    "\n",
    "def kalman_filter(x, P):\n",
    "    for n in range(len(measurements)):        \n",
    "        # measurement update\n",
    "        Z = matrix([[measurements[n]]])\n",
    "        y = Z - (H*x)\n",
    "        S = H * P * H.transpose() + R\n",
    "        K = P * H.transpose() * S.inverse()\n",
    "        x = x + (K*y)\n",
    "        \n",
    "        P = (I - (K * H)) * P\n",
    "        # prediction\n",
    "        x = (F * x) + u\n",
    "        P = F * P * F.transpose()\n",
    "    return x,P\n",
    "\n",
    "############################################\n",
    "### use the code below to test your filter!\n",
    "############################################\n",
    "\n",
    "measurements = [1, 2, 3]\n",
    "\n",
    "x = matrix([[0.], [0.]]) # initial state (location and velocity)\n",
    "P = matrix([[1000., 0.], [0., 1000.]]) # initial uncertainty\n",
    "u = matrix([[0.], [0.]]) # external motion\n",
    "F = matrix([[1., 1.], [0, 1.]]) # next state function\n",
    "H = matrix([[1., 0.]]) # measurement function\n",
    "R = matrix([[1.]]) # measurement uncertainty\n",
    "I = matrix([[1., 0.], [0., 1.]]) # identity matrix\n",
    "\n",
    "print(kalman_filter(x, P))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking ahead\n",
    "\n",
    "Particle Filters\n",
    "* Easy to implement\n",
    "* Powerful\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
