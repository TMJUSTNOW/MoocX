Now when Skinner was first studying rats in his Skinner box, he actually made
his own food pallets, and that was quite tedious. So he wondered what would
happen if, instead of reinforcing every level press, he actually spaced out
some of those reinforcers. And this is how he discovered an entire field of
study, of schedules of reinforcement. There are many different schedules, but
the two we'll just discuss briefly here are ratio schedules and interval
schedules. We have a ratio schedule and I could have a fixed ratio of five,
which means every fifth response is reinforced. We also have interval
schedules. Those are time schedules, so I could have a fixed interval of 30
seconds. That would mean that the first response that occurred after 30 seconds
was reinforced. Skinner famously compared rats in his Skinner box to humans by
looking at humans in casinos. On a variable schedule, reinforcement occurs on a
variable schedule, meaning perhaps after every ten responses, after every 20
responses. This type of schedule engenders a lot of behavior. You can just go
to Las Vegas and watch people at the slot machines pulling the levers. They're
no different than rats pressing levers in their Skinner boxes. Skinner studied
rats in Skinner boxes. The behavior first has to occur before it can be
reinforced. We can use shaping, which is reinforcing successive approximations
to the target behavior. And we can generate different types of behavior through
schedules of reinforcement. Be sure to read the pdf in the instructor's notes
on schedules of reinforcement. We're going to talk more about operant
conditioning, however, this time with another animal, sea lions.
