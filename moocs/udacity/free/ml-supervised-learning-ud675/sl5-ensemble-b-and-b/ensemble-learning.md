## Introduction
Lets think about spam email. 

Normally we think of this as a classification task, right, where we're going to take some email and we're going to decide if it's spam or not. I don't want you to try to think of some complicated rule that you might come up with that would capture spam email. Instead, I want you to come up with some simple rules that are indicative of spam email. Okay, so let me be specific, Michael. We have this problem with spam email. That is, you you're going to get some email message and you want some computer program to figure out automatically for you if something is a piece of spam or it isn't. And I want you to help write a set of rules that'll help me to figure that out. And I want you to think about simple rules, so can you think of any simple rules that might indicate that something is spam? M: Alright I can, yeah I can think of some simple rules. I don't think they would be very good, but they might be better than nothing. Like if, for example, it mentions how manly I am, I, I would be willing to believe that was a spam message. So like, if the body of the message contains the word manly.

## Ensemble Learning Simple Rules
So, the characteristic of  ensemble learning is first, that  you take a bunch of simple  rules, all of which kind of make  sense and that you can see as  sort of helping, but on their  own, individually, don’t give you  a good answer. And then you  magically combine them in  some way to create a more  complex rule, that in fact, works  really well. And ensemble  learning algorithms have a sort  of basic form to them that can  be described in just one or two  lines. So let me do that and then we can start wondering a little bit how we're going to make that  real. So here's the basic form of an ensemble learning algorithm. Basically you learn over a  subset of the data, and that generates some kind of a rule. And then you learn over another  subset of the data and that generates a different rule. And then you learn over another subset of  the data and that generates yet a third rule, and yet a fourth rule, and yet a fifth rule, and so on  and so forth. And then eventually you take all of those rules and you combine them into one of  these complex rules. So, we might imagine in the email case that I might look at a small subset  of email that I know is already spam and discover that the word manly shows up in all of them  and therefore pick that up as a rule. That's going to be good at that subset of mail, but not  necessarily be good at the other subset of mail. And I can do the same thing and discover that a  lot of the spam mails are in fact short or a lot of them are just images or just URLs and so on  and so forth. And that's how I learn these rules -- by looking at different subsets. Which is why  you end up with rules that are very good at a small subset of the data, but aren't necessarily good at a large subset of the data. And then after you've collected these rules, you combine  them in some way, and there you go. And  that's really the beginning and the end of ensemble learning.

## Ensemble Learning Example

It's basically the same kind of argument you make for cross-validation. You take a random bunch of subsets. You don't get trapped by one or two points that happen to be wrong because they happen to be wrong because of noise or whatever and you sort of average out all of the variances and the differences. And oftentimes it works. And, in practice, this particular technique, ensemble learning, does quite well in getting rid of overfitting.

This particular version, where you take a random subset and you combine by the mean, it's called **bagging**, the **bags are the random subsets**. It also has another name which is called **bootstrap aggregation**. Bootstrap usually refers to pulling yourself up by your bootstraps.   C: Yeah, I like my answer better. So, each of the subsets are the boots and the averaging is the  strap. And there you go. So, regardless of whether you call it bootstrap aggregation or you call it  bagging, you'll notice it's not what I said we were going to talk about during today's discussion.  I said we were going to talk about boosting. So we're talking about bagging but we're going to  talk about boosting. The reason I wanted to talk about bagging is because it's really the simplest  thing you can think of and it actually works remarkably well. But there are a couple of things  that are wrong with it, or a couple of things you might imagine you might do better that might  address some of the issues and we're going to see all of those when we talk about boosting  right now.

## Ensemble Learning: Boosting


## Ensemble Learning: Quiz

### Defining Error again
We already know some definitions of error. For classifier or regression algorithm, we take the squared difference between the correct labels. 
For classification problems, that would be the same as squared error, except that it's doesn’t really need to be squared. That is to say, if the outputs are zeroes and ones, the squared error is just whether or not there's a mismatch. So it could just be the total number of wrong answers. We might define an error rate or an error percentage as the total number of  mismatches over the total number of examples. And that tells us whether we're at 85% or 92%  or whatever.

But implicit in that,is the  idea that every single example is equally important. So, that's not always the case. Now you  might remember from the very first talk that we had, we talked about distributions over  examples. We said that, you know, learning only happens if your training set has the same  distribution as your future testing set. And if it doesn't, then all bets are off and it's very difficult  to talk about induction or learning. That notion of distribution is implicit in everything that we've  been doing so far, and we haven't really been taking it into account when we've been talking  about error. So here's another definition of error and you tell me if you think it makes sense,  given what we just said. So, this is my definition of error. 

Let D be the distribution, H be the hypothesis, and C is underlying true concept. Now, we can define error as probability, given the underlying distribution, that I will disagree with the true concept on some particular instance X.


## Weak Learning
