Thewidespread misunderstanding of randomness causes a lot of problems.

Todaywe’re going to explore a concept that causes a lot of human misjudgment. It’scalled the bias from insensitivity to sample size, or, if you prefer,the law ofsmall numbers.

Insensitivityto small sample sizes causes a lot of problems. 

\* * *

If Imeasured one person, who happened to measure 6 feet, and then told you thateveryone in the whole world was 6 feet, you’d intuitively realize this is amistake. You’d say, you can’t measure only one person and then draw such aconclusion. To do that you’d need a much larger sample. 

And, ofcourse, you’d be right. 

Whilesimple, this example is a key building block to our understanding of howinsensitivity to sample size can lead us astray.

AsStuard Suterhland writes in [Irrationality](http://www.amazon.com/gp/product/B0046ZRNLE/ref=as_li_qf_sp_asin_il_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=B0046ZRNLE&linkCode=as2&tag=farnamstreet-20):

Before drawing conclusions from information about a limited numberof events (a sample) selected from a much larger number of events (thepopulation) it is important to understand something about the statistics ofsamples.

In [Thinking, Fast and Slow](http://www.amazon.com/gp/product/0374533555/ref=as_li_qf_sp_asin_il_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=0374533555&linkCode=as2&tag=farnamstreet-20), Daniel Kahnemanwrites “A random event, by definition, does not lend itself to explanation, butcollections of random events do behave in a highly regular fashion.” Kahnemencontinues, “extreme outcomes (both high and low) are more likely to be found insmall than in large samples. This explanation is not causal.”

We allintuitively know that “the results of larger samples deserve more trust thansmaller samples, and even people who are innocent of statistical knowledge haveheard about this law of large numbers.”

Theprinciple of regression to the mean says that as the sample size grows largerresults should converge to a stable frequency. So, if we’re flipping coins, andmeasuring the proportion of times that we get heads, we’d expect it to approach50% after some large sample size of, say, 100 but not necessarily 2 or 4.

In ourminds, we often fail to account for the accuracy and uncertainty with a givensample size. 

While weall understand it intuitively, it’s hard for us to realize in the moment ofprocessing and decision making that larger samples are better representationsthan smaller samples. 

Weunderstand the difference between a sample size of 6 and 6,000,000 fairly wellbut we don’t, intuitively, understand the difference between 200 and 3,000.

\* * *

This biascomes in many forms.

In a telephone poll of 300 seniors, 60% support thepresident.

If you had to summarize the message of this sentence in exactlythree words, what would they be? Almost certainly you would choose “elderlysupport president.” These words provide the gist of the story. The omitteddetails of the poll, that it was done on the phone with a sample of 300, are ofno interest in themselves; they provide background information that attractslittle attention.” Of course, if the sample was extreme, say 6 people, you’dquestion it. Unless you’re fully mathematically equipped, however, you’llintuitively judge the sample size and you may not react differently to a sampleof, say, 150 and 3000. That, in a nutshell, is exactly the meaning of thestatement that “people are not adequately sensitive to sample size.”

Part ofthe problem is that we focus on the story over reliability, or, robustness, ofthe results.

Systemone thinking, that is our intuition, is “not prone to doubt. It suppressesambiguity and spontaneously constructs stories that are as coherent aspossible. Unless the message is immediately negated, the associations that itevokes will spread as if the message were true.”

Consideringsample size, unless it’s extreme, is not a part of our intuition.

Kahnemanwrites:

The exaggerated faith in small samples is only one example of a moregeneral illusion – we pay more attention to the content of messages than toinformation about their reliability, and as a result end up with a view of theworld around us that is simpler and more coherent than the data justify.Jumping to conclusions is a safer sport in the world of our imagination than itis in reality.

\* * *

Inengineering, for example, we can encounter this in the evaluation of precedent.

StevenVick, writing in [Degrees of Belief: Subjective Probability and Engineering Judgment](http://www.amazon.com/gp/product/0784405980/ref=as_li_qf_sp_asin_il_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=0784405980&linkCode=as2&tag=farnamstreet-20), writes:

If something has worked before, the presumption is that it will workagain without fail. That is, the probability of future success conditional onpast success is taken as 1.0. Accordingly, a structure that has survived anearthquake would be assumed capable of surviving with the same magnitude anddistance, with the underlying presumption being that the operative causalfactors must be the same. But the seismic ground motions are quite variable intheir frequency content, attenuation characteristics, and many other factors,so that a precedent for a single earthquake represents a very small samplesize.

[Bayesian reasoning](http://www.farnamstreetblog.com/2012/12/thomas-bayes-and-bayess-theorem/) tells us that asingle success, absent of other information, raises the likelihood of survivalin the future.

In a waythis is related to robustness. The more you’ve had to handle and you stillsurvive the more robust you are.

Let’slook at some other examples.

\* * *

Hospital

DanielKahneman and Amos Tversky demonstrated our insensitivity to sample size withthe following question:

A certaintown is served by two hospitals. In the larger hospital about 45 babies areborn each day, and in the smaller hospital about 15 babies are born each day.As you know, about 50% of all babies are boys. However, the exact percentagevaries from day to day. Sometimes it may be higher than 50%, sometimes lower.For a period of 1 year, each hospital recorded the days on which more than 60%of the babies born were boys. Which hospital do you think recorded more suchdays?

1. The larger     hospital
2. The smaller hospital
3. About the same (that is,     within 5% of each other)

Mostpeople incorrectly choose 3. The correct answer is, however, 2.

In [Judgment in Managerial Decision Making](http://www.amazon.com/gp/product/0470049456/ref=as_li_qf_sp_asin_il_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=0470049456&linkCode=as2&tag=farnamstreet-20),Max Bazerman explains:

Most individuals choose 3, expecting the two hospitals to record asimilar number of days on which 60 percent or more of the babies board areboys. People seem to have some basic idea of how unusual it is to have 60percent of a random event occurring in a specific direction. However,statistics tells us that we are much more likely to observe 60 percent of malebabies in a smaller sample than in a larger sample.” This effect is easy tounderstand. Think about which is more likely: getting more than 60 percentheads in three flips of coin or getting more than 60 percent heads in 3,000flips.

\* * *

Anotherinteresting example comes from Poker.

Overshort periods of time luck is more important than skill. The more luckcontributes to the outcome, the larger the sample you’ll need to distinguishbetween someone’s skill and pure chance.

DavidEinhorn explains.

People ask me “Is poker luck?” and “Is investing luck?”

The answer is, not at all. But sample sizes matter. On any given daya good investor or a good poker player can lose money. Any stock investment canturn out to be a loser no matter how large the edge appears. Same for a pokerhand. One poker tournament isn’t very different from a coin-flipping contestand neither is six months of investment results.

On that basis luck plays a role. But over time – over thousands of hands against a varietyof players and over hundreds of investments in a variety of market environments– skill wins out.

As thenumber of hands played increases, skill plays a larger and larger role and luckplays less of a role.

\* * *

Butthis goes way beyond hospitals and poker. Baseball is another good example. Over along season, odds are the best teams will rise to the top. In the short term,anything can happen. If you look at the standing 10 games into the season, oddsare they will not be representative of where things will land after the full162 game season. In the short term, luck plays too much of a role.

In [Moneyball](http://www.amazon.com/gp/product/0393338398/ref=as_li_qf_sp_asin_il_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=0393338398&linkCode=as2&tag=farnamstreet-20), Michael Lewis writes “In afive-game series, the worst team in baseball will beat the best about 15% ofthe time.”

\* * *

Ifyou promote people or work with colleagues you’ll also want to keep this bias in mind.

If youassume that performance at work is some combination of skill and luck you caneasily see that sample size is relevant to the reliability of performance.

Thatperformance sampling works like anything else, the bigger the sample size thebigger the reduction in uncertainty and the more likely you are to make gooddecisions.

Thishas been studied by one of my favorite thinkers, James March. He calls is the [false record effect](http://www.farnamstreetblog.com/2011/08/promoting-people-in-organizations/).

Hewrites:

False Record Effect. A group of managers of identical (moderate)ability will show considerably variation in their performance records in theshort run. Some will be found at one end of the distribution and will be viewedas outstanding; others will be at the other end and will be viewed asineffective. The longer a manager stays in a job, the less the probabledifference between the observed record of performance and actual ability. Timeon the job increased the expected sample of observations, reduced expectedsampling error, and thus reduced the change that the manager (or moderateability) will either be promoted or exit.

Hero Effect. Within a group of managers of varying abilities, thefaster the rate of promotion, the less likely it is to be justified.Performance records are produced by a combination of underlying ability andsampling variation. Managers who have good records are more likely to have highability than managers who have poor records, but the reliability of thedifferentiation is small when records are short.

(Irealize promotions are a lot more complicated than I’m letting on. Some jobs,for example, are more difficult than others. It gets messy quickly and that’spart of the problem. Often when things get messy we turn off our brains andconcoct the simplest explanation we can. Simple but wrong. I’m only pointingout that sample size is one input into the decision. I’m by no means advocatingan “experience is best” approach, as that comes with a host of other problems.)

\* * *

Thisbias is also used against you in advertising.

The nexttime you see a commercial that says “4 out of 5 Doctors recommend ….” Theseresults are meaningless without knowing the sample size. Odds are pretty goodthat the sample size is 5.

\* * *

Largesample sizes are not a panacea. Things change. Systems evolve and faith inthose results can be unfounded as well.

The key,at all times, is to think.

This biasleads to a whole slew of things, such as:

– under-estimating risk

– over-estimating risk

– undue confidence in trends/patterns

– undue confidence in the lack of side-effects/problems

 

Source

[https://www.farnamstreetblog.com/2013/05/mental-model-bias-from-insensitivity-to-sample-size/](https://www.farnamstreetblog.com/2013/05/mental-model-bias-from-insensitivity-to-sample-size/)